Por que aprender Inteligência Artificial?

 - Potencial para transformar a maneira como realizamos
   uma série de tarefas, economizando inúmeras horas de
   esforço humano.

 - Auxiliar a redigir texto como emails, resumos,
   artigos e marketing.

 - Auxiliar na codificação e obtenção de sugestões de
   códigos e melhorias em software.
   
 - Se você for capaz de detalhar as etapas de uma tarefas
   para uma IA de forma clara e lógica, existe uma boa chance
   de que a IA seja capaz de assumir essa tarefa para você.

 - Em alguns casos, a IA pode até mesmo não apenas realizar
   a tarefa, mas também fornecer um ponto de partida sólido
   para tarefas mais repetitivas.

 - Conforme pesquisa do MIT, que foi divulgada na conceituda
   revista Science, inteligências artificiais que geram texto
   podem ser muito úteis para tarefas simples do dia a dia,
   como redigir emails ou criar relatórios breves.
   O usar chatbots de IA, a produtividade aumenta em 40%,
   enquanto a qualidade do trabalho melhora em 18%.

 - Um estudo da IBM de 2022 revela que quase metade das
   empresas do Brasil, especificamente 41%, faem uso de IA
   em suas operações cotidianas. Os números indicam um
   aumento significativo, especificamente no contexto
   após a pandemia de Covid-19. Além disso, o estudo aponta
   que dois terços das empresas pesquisadas, ou seja 66%,
   estão no processo de implementar IA ou têm intenções
   de faze-lo em breve.


Assistente de IA do Curso Em Vídeo

 - Criado para acessorar os alunos que estiverem fazendo o 
   curso de IA, treinado com dados e informações do curso
   em questão.

 - https://www.cursoemvideo.link/helpia
 - https://chatgpt.com/g/g-5lw3vTPpm-cev-curso-de-ia


 - O assistente possui opções pre configuradas para auxiliar
   os alunos, com revisões de aulas do curso, criação de 
   exercícios e revisão de prompts.


LLMs Localmente

 - Uma ferramenta muito útil e interessante para rodar
   modelos de IA localmente é o LLM Studio.

 - Uma ferramente gratuita que permite instalar modelos
   de diferentes empresas com diferentes propósitos.

 - https://lmstudio.ai/


Aplicações da IA

 - Assistentes virtuais: Siri, Alexa e Google Assistent IA
   para entender nossas perguntas e fornecer respostas
   relevantes.

 - Carros autônomos: Veículos autônomos usam IA para
   perceber o ambiente ao seu redor e tomar decisões
   de direção.

 - Sistemas de recomendação: Serviços como Netflix e Amazon
   usam IA para sugerir filmes, músicas ou produtos com base
   em nosso histórico de uso.

 - Medicina: A IA é usada para analisar imagens médicas,
   prever doenças e personalizar tratamentos.


Desafios da IA

 - Preocupações éticas sobre a privacidade dos dados e
   o uso indevido da IA.

 - Potencial perda de empregos devido à automação.

 - Fornecimento de informações incorretas.

 - Dificuldade de garantir que os sistemas de IA ajam
   de maneira justa e imparcial.


Conclusão

 - A IA é uma ferramenta poderosa com o potencial de
   transformar muitas áreas de nossas vidas.

 - Embora existam desafios a serem superados, as possibilidades
   oferecidas pela IA são emocionantes.

 - À medida que a tecnologia continua a evoluir, podemos
   esperar ver ainda mais aplicações inovadoras de IA no
   futuro.


Machine Learning

 - Máquinas são capazes de aprender

 - Aprendizado de máquina, ou "Machine Learning" em inglês.

 - É uma subárea da inteligência artificial.

 - Foca em desenvolver sistemas capazes de aprender a partir
   de dados.

 - Em vez de serem explicitamente programados para realizar
   uma tarefa específica, esses sistemas são treinados
   usando grandes conjuntos de dados e algoritmos que lhes
   permitem melhorar seu desenpenho com base na experiência.

 - Imagine ensinar uma criança a reconhecer frutas
   mostrando-lhe diversas imagens. Quanto mais imagens
   ela vê, melhor ela se torna em indentificar cada fruta.

 - De forma semelhante, no aprendizado de máquina, um modelo
   de computador é "treinado" usando um conjunto de dados para,
   por exemplo, reconhecer padrões, fazer previsões ou tomar
   decisões.

 - E resumo, o aprendizado de máquina é o coração pulsante
   que permite que a IA reaja e evolua em resposta ao mundo ao
   seu redor.


Deep Learning

 - Deep learning, ou "Aprendizado Profundo" em tradução livre.

 - É uma subcategoria do aprendizado de máquina, que, por sua
   vez, é uma vertente da inteligência artifical.

 - O deep Learning é inspirado na estrutura e função do
   cérebro humano, especificamente em uma construção chamada
   redes neurais.

 - Em Deep Learning, utiliza-se uma versão avançada dessas
   redes, conhecida como redes neurais profundas.

 - Estas redes possuem múltiplas camadas de neurônios artificiais,
   permitindo a elas processar dados de forma hierárquica e 
   complexa.

 - Por exemplo, ao processar uma imagem, as camadas iniciais
   podem detectar bordas, as camadas intermediárias podem
   reconhecer formas e as camadas mais profundas podem
   identificar objetos.

 - O que torna o Deep Learning especial é sua capacidade
   excepcional de reconhecer padrões em grandes conjuntos
   de dados.

 - Isso tornou possível avanços significativos em tarefas
   complexas de IA, como reconhecimento de voz, tradução
   automática e identificação de objetos em imagens.

 - Em essência, o Deep Learning é uma ferramenta poderosa
   que permite que máquinas "vejam", "ouçam" e "entendam"
   o mundo de maneira mais semelhante aos humanos, levando
   a inovações supreendentes na tecnologia de inteligência
   artificial.


LLMs (Large Language Models)

 - Modelo de Linguagem em Larga Escala.

 - Os modelos de Linguagem de grande escala (LLMs) são
   um tipo de inteligência artificial que são treinados
   em grandes quantidades de dados de texto.

 - Esses dados podem incluir livros, artigos, códigos e
   outros formatos de texto.

 - Os LLMs são capazes de aprender padrões e relacionamentos
   no texto, o que os permite gerar texto semelhante ao 
   humano, traduzir idiomas, escrever diferentes tipos de 
   conteúdo criativo e responder às suas perguntas de forma
   informativa.

 - Os LLMs ainda estão em desenvolvimento, mas já têm o 
   potencial de revolucionar a forma como interagimos com
   a tecnologia.

 - Por exemplo, os LLMs podem ser usados para criar
   assistentes virtuais mais inteligentes, que podem
   entender e responder melhor às nossas solicitações.

 - Os LLMs também podem ser usados para criar ferramentas
   de tradução mais precisas e eficientes.

 
Chatbot

 - Simulando Conversas humanas

 - Chatbos são pogramas de computador projetados para
   simular conversas humanas.

 - Geralmente alimentado por técnicas de processamento
   de linguagem natural e aprendizado de máquina, permitindo-lhe
   entender, responder e interagir com os usuários de forma
   natural e contextualizada.

 - Enquanto os chatbots mais simples operam com base em
   regras predefinidas e respostas programadas, os alimentados
   po IA podem aprender com interações anteriores, adaptar-se
   ao longo do tempo e fornecer respostas mais personalizadas.

 - Esses chatbots avançados podem entender variações na
   linguagem, responder a perguntas não previstas e até
   mesmo indentificar o humor ou intenção do usuário.

 - Os chatbots são comumente usados em atendimento ao cliente,
   plataformas de mensagens, websites e aplicativos, oferecendo
   respostas rápidas, automação e suporte 24/7.

 - Em resumo, chatbots são a interseção da IA com a comunicação
   humana, tornando as interações digitais mais eficientes e
   amigáveis.

 - O ChatGPT e o Google Gemini são chatbots.


NLP (Natural Language Processing)

 - Processamento de Linguagem Natural (PLN)

 - PLN, ou processamento de Linguagem Natural, é um subcampo
   da inteligência artificial focado na interação entre
   computadores e linguagem humana.

 - Seu objetivo principal é permitir que máquinas entendam,
   interajam e respondam à linguagem humana de uma maneira que
   seja tanto valiosa quanto significativa.

 - Usando as técnicas de PLN, sistemas de IA podem realizar
   tarefas como tradução automática, análise de sentimentos,
   resumos automáticos e até mesmo compreensão e geração de
   texto complexo.

 - Por exemplo, assistente como Siri e Alexa dependem
   fortemente do PLN para entender e responder às solicitações
   dos usuários.

 - Em essência, o PLN busca construir pontes entre máquinas
   e humanos atráves da linguagem, tornando possível a
   comunicação fluida e a extração de informações valiosas
   dos textos.

 - É graças ao PLN que a IA pode "ler", "ouvir" e "falar"
   conosco.


Tokens

 - Tijolos fundamentais

 - No âmbito da inteligência artificial, especialmente
   quando se trata de PLN, um "token" refere-se a uma
   unidade individual de informação ou dado.

 - Geralmente, ao trabalhar com texto, um token pode ser
   uma palavra, uma frase ou até mesmo um caractere,
   dependendo do contexto.

 - Por exemplo, ao separar em tokens a frase "Aprendizado
   de máquina é fascinante", podemos obter os tokens:
   "Aprendizado", "de", "máquina", "é" e "fascinante".

 - O processo de separar um texto em tokens depéndendo
   do contexto inserido, chama-se "tokenização".

 - A tokenização é um processo fundamental em muitos
   processos de PLN.

 - Ao converter os textos em tokens, os algoritmos de
   IA podem analisar, compreender e processar a linguagem
   humana de maneira mais eficaz.

 - Essa transformação ajuda na tarefa de identificar
   padrões, compreeder contextos e realizar operações,
   como análise de sentimentos, tradução automática e muitas
   outras aplicações relacionadas ao texto.

 - Portanto, no contxto da IA, tokens são os "tijolos"
   fundamentais que permitem que máquinas entendam e
   manipulem a linguagem humana.

 - O ChatGPT 3 processa 4096 tokens por solicitação.
   Isso inclui tanto o prompt quanto a resposta. (No
   momento do vídeo). O ChatGPT-5 (versão atual) pode
   lidar com 16000 (16k) tokens por solicitação na sua
   versão gratuita e 200000 (200k) tokens na sua versão
   paga.

 - Por exemplo, se você solicitar ao ChatGPT 3 para gerar
   um poema de 4097 palavras, ele será capaz de gerar as 
   primeiras 4096 palavras, mas não poderá gerar a útlima
   palavra.

 - O limite de tokens foi imposto pela OpenAI para evitar
   o uso excessivo de recursos.

 - O ChatGPT 3 é um modelo de linguagem grande e complexo,
   e processar um grande número de tokens pode exigir uma
   quantidade significativa de memória e processamento.

 - O ChatGPT 4 processa até 32768 (23.7k) tokens por
   solicitação. Isso inclui tanto o prompt quanto a
   resposta.

 - O ChatGPT 4 tem duas variantes: ChatGPT 4-8K que possui
   um limite de 8192 (8.1) tokens e o ChatGPT 4-32K que
   possui um limite de 32768 (32.7K) tokens.

 - O Gemini processa um número ilimitado de tokens por
   solicitação. Isso significa que ele pode gerar texto
   de qualquer comprimento, desde um único token até um
   texto de milhões de palavras. (No momento do vídeo).

 - o Gemini é capaz de processar um número ilimitado de
   tokens porque é um modelo de linguagem de transformador.

 - Os transformadores são um tipo de modelo de linguagem
   que usa um mecanismo chamado atenção para se concentrar
   nas partes mais importantes do texto.

 - Isso permite que eles processem texto de qualquer
   comprimento sem perder o contexto.


Prompt

 - Instruções para obtenção de resultados.

 - No contexto da inteligência artificial, especialmente
   em modelos de linguagem, um "prompt" é uma instrução
   ou estímulo dado ao sistema para obter uma resposta
   ou um comportamento específico.

 - Geralmente apresentado na forma de um texto ou frase,
   o prompt serve como gatilho para o modelo de IA,
   indicando o tipo de informação ou resposta que o usuário
   deseja.

 - Por exemplo, ao interagir com um modelo de linguagem
   como o GPT da OpenAI, se você inserir o prompt "Traduza
   a seguinte frase para o espanhol:", o modelo entenderá que
   deve realizar uma tarefa de tradução com base no texto
   subsequente fornecido (em língua portuguesa).

 - Prompts são essenciais para direcionar e moldar as
   saídas de modelos de IA, garantindo que as respostas
   sejam relevantes e de acordo com as intenções do
   usuário.

 - Eles funcionam como uma espécie de "pergunta" ou
   "comando" que guia a máquina em sua resposta.


ChatBot de IA Vs Buscador

 - Embora ambos, um chatbot de IA e um buscador, operem
   utilizando bases de dados para fornecer respostas e
   interagir com os usuários, a maneira como eles acessam
   e usam essas informações é fundamentalmente diferente.

 - Os chatbots de IA, são treinados em um vasto conjunto
   de dados de milhões de páginas da internet, mas eles
   não têm a capacidade de acessar ou recuperar informações
   em tempo real da internet após o treinamento. (Na época
   do vídeo, hoje eles já possuem essa capacidade).

 - Eles não "lembram" ou "sabem" informações específicas, em
   vez disso, geram respostas com base nos padrões que
   aprenderam durante o teinamento.

 - Por outro lado, um buscador, como o Google Search, indexa
   a web em tempo real e mantém um banco de dados atualizado
   das páginas da web existentes.

 - Quando você insere uma consulta, o buscador procura
   em seu índice de páginas da web para econtrar as mais
   relevantes e atualizadas informações para a sua pesquisa.
  
 - Diferentemente dos chatbots de IA, os buscadores têm
   acesso a informações da internet e pódem fornecer dados
   atualizados e específicos.

 - Essa distinção é essencial quando se considera a 
   precisão e a atualidade das informações fornecidas.

 - Um chatbot de IA pode ser útil para fornecer respostas
   gerais com base em padrões de linguagem, mas para
   informações atualizadas ou específicas, um buscador
   seria a ferramenta mais adequada.


IAs de Texto Generativo

 - As IAs de texto genrativo, bastante populares hoje em
   dia, têm "cperebros" compostos por bilhões de "neurônios"
   artificiais.

 - Esse arranjo de neurônios é o que chamamos de
   arquitetura transformadora, um tipo complexo de rede
   neural. Aqui estão alguns pontos chaves para entender:

   As IAs são como grandes equações matemáticas: Em vez de
   uma simples equação como "f(x) = x^2", imagine uma função
   com milhares de variáveis que resulta em milhares de
   possíveis respostas.

   Essa é a essência do que essas IAs estão fazendo.

 - IAs entendem sentenças através de "tokens": As IAs
   dividem o texto em pedaços menores chamados tokens, que
   podem ser frases, palavras ou subpalavras. Por exemplo,
   a frase "Eu não gosto" pode ser dividida em "Eu", "não"
   e "gosto".

   Cada token é então convertido em uma série de números
   para que a IA possa precessa-lo.

   IAs preveem o próximo token na sequência: Baseando-se
   nos tokens anteriores, as IAs tentam prever o próximo
   token da sequência. Por exemplo, depois de "Eu não
   gosto de", a IA poderia prever a palavra "maçãs".

   Cada nova palavra que a IA escrever será baseada no
   que ela já viu e já escreveu antes.

   IAs analisan todos os tokens simultaneamente: Ao
   contrário do humanos que leem da esquerda para a
   direita ou da direita para a esquerda, as IAs
   analisam todos os tokens ao mesmo tempo.

 - É importante notar que as palavras "pensar", "cérebro"
   e "neurônio" são formas de nos ajudar a entender melhor
   o que está acontecendo, mas são metáforas.

   Estes modelos não estão realmente pensando, são apenas
   funções matemáticas complexas. Eles não tem cérebros, mas
   sim redes neurais artificiais. E eles não tem neurônios
   biológicos, mas sim representações numéricas.

   A natureza exata dessas IAs é um tópico ativo de
   pesquisa e debate filosófico. É fácil cair na
   armadilha de pensar nelas como seres pensantes semelhantes
   aos humanos, especialmente com a forma como são
   retratadas na méidia.

   Entretanto, se achar útil pensar na IA como um "ser"
   para entender como ela funciona, não há problema nisso.

   Muitas pessoas fazem isso e pode ser um método eficaz
   de aprendizado.


Engenharia de Prompt

 - Ato de ensinar uma inteligência artificial (IA) a 
   realizar uma tarefa específica é frequentemente
   referido como "prompting".

 - Esse processo é um pouco como dar instruções a um
   amigo: fornecemos à IA uma série de orientações
   (o "prompt") e então ela se esforça para executar a
   tarefa solicitada.

   Estes prompts podem ser tão simples quanto uma única
   pergunta: "Qual é o clima hoje?".

   Ou tão complexo quanto um trecho inteiro de texto com
   vários parágrafos.

 - Imagine que você esta fazendo uma pergunta a um amigo
   muito inteligente, ou pedindo a ele para fazer algo.

 - Essa é basicamente a essência do "prompting" en IA:
   estamos dando à máquina uma tarefa para resolver e
   aguardando sua resposta, que será baseada no que ela
   aprendeu durante seu treinamento.

 Exemplos:

   - Um exemplo básico de uma instrução seria perguntar
     diretamente algo como: "Quanto é 1000 * 6000?".

   - Digamos que você está lendo um artigo sobre a indepen-
     dência do Brasil e quer rapidamente capturar as ideias
     principais do artigo, então você mostra para a IA o
     que você está lendo e pede um resumo.

     O prompt para essa solicitação poderia ser: "Resuma o
     texto acima em uma única sentença."

   - Podemos usar a seguinte solicitação para reposcionar
     nomes em uma lista:

     "Temos uma lista de nomes de usuários contendo o
      primeiro e o último nome. Precisamos que os nomes
      fiquem no formato: Último, Primeiro'".

   - Este é um exemplo mais complicado, Nele, você vai
     perceber como o modelo pode ir além das instruções.
     Não há uma indicação explicita de como deve ser a
     mudança para o e-mail e telefone, mas a IA fará a
     substituição de maneira adequada.

     "Leia o email a seguir e remova todas as informações
      de identificação pessoal, substituindo-as com o espaço
      reservado apropriado. Por exemplo, substitua o nome
      'Gustavo Guanabara' por '[NOME]' e garanta que todas
      as informações pessoais foram substituídas apropria-
      damente".


Role Prompting

 - O Prompting de Atuação é uma técnica utilizada no
   controle do estilo de texto gerado por inteligência
   artificial. Essa técnica é muito versáril e oferece
   várias aplicações interessantes.

 - Melhoria de precisção: Pode ser usado para aumentar
   a precisão da IA em tarefas específicas, como resolver
   problemas matemáticos.

 - Controle de estilo: Implementar o Prompting de 
   atuação é simples e envolve instruir a IA a assumir
   um papel específico, como "incorporar um crítico de
   moda" ou "agir como um especialista". Ao fazer isso,
   a IA pode escrever com o estilo ou tom desejado e até
   mesmo alterar a profundidade das informações apresentadas.

 - Em resumo, o Prompting de Atuação é uma abordagem
   poderosa para moldar a maneira como a IA responde,
   tornando-a uma ferramenta útil em várias aplicações.

 Exemplos:

   - Vamos a um exemplo simples, sem usar o Prompting de
     atuação. Vamos pedir uma avaliação para uma hambur-
     gueria.

     "Escreva uma avaliação sobre uma hamburgueria chamada
      Guanabara".

   - O resultado obtido com o exemplo anterior já é
     muito bom, mas vamos ver o que acontece quando a
     IA assume o papel de crítico gastronômico.

     "Você é um crítico gastronômico. Escreva uma avali-
      ação sobre uma hamburgueria chamada Guanabara".

   - Agora vamos dar um passo adiante e faze-lo assumir
     o papel de redator do guia Michelin.

     "Você é um crítico gastronômico que escreve para o
      Guia Michelin. Escreva uma avaliação sobre uma
      hamburgueria chamada Guanabara".

 - Ao usar uma IA para escrever um e-mail, é importante
   pensar no "trabalho" que você quer que ele faça. O 
   jeito como o e-mail vai sair depende do que você
   pedir para o robô fazer.

 - Por exemplo, digamos que você precisa mandar um e-mail
   para um cliente avisandp que vai haver um atraso na
   entrega de um produto por causa de problemas no trans-
   porte. Você quer que o cliente entenda a situação, mas
   também não quer que ele perca a confiança no seu ser-
   viço. Dependendo de como você "programa" na IA, o e-mail
   pode ter estilos diferentes.

 Exemplos:

   - Por exemplo, você deseja que a IA se comporte como
     um especialista em comunicação, cujo estilo pode ser
     claro, profissional e direto ao ponto.

     "Você é um especialista em comunicação. Elabore um
      e-mail para seu cliente avisando sobre atraso no
      cronograma de entrega devido a problemas logísticos".

   - Peça para se comportar como um especialista de marke-
     ting para se apoiar mais na persuasão, na positividade
     e na construção de relacionamento.

     "Você é um especialista em marketing. Elabore um e-mail
      para um cliente avisando sobre um atraso no cronograma
      de entrega devido a problemas logísticos".

   - Se comportando como um representante de atendimento
     ao cliente, podemos ter um resultado mais relacional
     e orientado para soluções.

     "Você é um representante de atendimento ao cliente.
      Elabore um e-mail para um cliente avisando sobre um
      atraso no cronograma de entrega devido a problemas
      logísticos".

 - A técnica de definir o "papel" é uma estratégia eficaz
   para moldar o que os modelos de IA generativos produzem.

 - Isso nos permite ajustar o estilo, o tom e a complexidade
   do texto gerado, tornando-o mais apropriado para diferentes
   situações ou públicos.

 - Seja ao criar um e-mail, redigir uma avaliação ou resolver
   um problema matemático, essa técnica pode melhorar siginifi-
   cativamente a qualidade e a precisão do resultado.

 - À medida que avançamos no entendimento das capacidades da
   IA, a definição de "papel" continuará sendo uma tática
   crucial na engenharia de prompt.


Showing Examples

 - Outra estratégia de prompt é a chamada "prompting com
   poucos disparos" (few-show prompting), que basicamente
   consiste em fornecer ao modelo de linguagem alguns exem-
   plos do que se espera que ele faça.

 - Esse tipo de instrução permite que a IA aprenda com base
   nesses poucos exemplos.

 Exemplos:

   - Tomemos como exemplo a situação em que estamos tentando
     classificar o feedback do cliente como positivo ou nega-
     tivo. Apresentamos ao modelo três exemplos de feedbacks'
     positivos ou negativos e, em seguida, mostramos a ele um 
     novo comentário ainda não classificado. O modelo, ao ob-
     servar os três exemplos iniciais classificados como posi-
     tivos ou negativos, utiliza essa informação para classi-
     ficar o novo comentário.

     "Aprenda com o modelo a seguir e complete a avaliação
      da última linha.
       - Ótimo produto: positivo
       - Não funcionou muito bem: negativo
       - Super útil, vale a pena: positivo
       - Não funciona:
      ".

 - Um caso de uso fundamental para a instrução com poucos
   exemplos é quando você precisa que a saída seja estruturada
   de uma forma específica que é defícil de explicar ao modelo.

 - Para entender isso, considere o próximo exemplo.

 Exemplos:

   - Vamos supor que você esteja realizando uma análise econô-
     mica e precise compilar os nomes e profissões de cidadãos
     conhecidos em cidades vizinhas, analizando artigos de jor-
     nais locais. Você quer que o modelo leria cada artigo e 
     gere uma lista de nomes e ocupações no formato: Primeiro
     e último nomes [PROFISSÃO]. Para fazer o modelo executar
     esta tarefa, você precisa fornecer alguns exemplos.

     "Aprenda como o modelo abaixo

     (forneça o modelo em texto)

     1. Bianca Lobo [ATRIZ]
     2. Ramiro Lobo [ENGENHEIRO DE SOFTWARE]
     3. Michelle Santos [PSICÓLOGA]
     ".

     Após o modelo ter sido fornecido, podemos informar o 
     texto real que queremos que ele análise.

     "Morador da cidade Gustavo Guanabara, um brilhante profes-
     sor, criou um canal de educação no Youtube e ficou famoso
     no mundo inteiro. Camila Lobo, uma jovem programadora,
     criou um aplicativo de investimentos na bolsa de valores e
     Kauê Linden, um famoso publicitário, é conheido por sua
     popular agência de marketing.
     
     Baseado nos textos e exemplos acima, liste os nomes dos
     moradores da cidade e suas profissões. Use o formato:
     Nome [PROFISSÃO].
     ".

 - O uso de instruções com poucos disparos (few-shot prompting)
   é uma estratégia eficaz que pode orientar o modelo a gerar
   respostas precisas e bem estruturadas.
     
 - Ao fornecer múltiplos exemplos, esse método permite que o
   modelo compreenda o formato de saída desejado e responda
   de acordo, tornando-se um método preferido em relação às
   instruções sem exemplos na maioria dos cenários.


Combinando Técnicas

 - Anteriormente, vimos que as instruções podem ser direfentes
   em formato e complexidade.

 - Essas instruções pode conter contexto, diretrized e vários
   exemplos de entradas e saídas.

 - Até agora, só olhamos para tipos separados de instruções.
   Juntar essas diferentes técnicas pode resultar em instru-
   ções mais eficazes.

 Exemplo 1 (papeis e Instruções):

   - Você pode combinar o papel que a inteligência artificial
     vai desempenhar com comandos específicos para fazer pergun-
     tas mais complicadas.

   - Por exemplo, você pode pedir para a IA agir como um histo-
     riador e, ao mesmo tempo, dar instruções para uma tarefa
     específica.

    "Você é um historiador especializado na hístória do Brasil.
     Escreva um breve resumo dos principais eventos e resul-
     tados da independência do país."

 Exemplo 2 (Contexto, instruções e exemplos):

   - Vamos tentar classificar Tweets como positivos ou nega-
     tivos.
     
   - O contexto é dado pela explicação sobre o Twitter
     e a tarefa de classificar tweets.

   - A instrução é dada na frase "Certifique-se de classificar
     o último tweet corretamente".

   - Os exemplos são mostrados com dois tweets, um positivo e
     um negativo.

   - A expectativa é que a inteligência artificial use essa
     combinação de contexto, instruções e exemplos para clas-
     sificar o último tweet corretamente.

   "O Twitter é uma plataforma de mídia social onde os usuá-
    rios podem postar mensagens curtas chamadas 'tweets'. Os
    tweets podem ser positivos ou negativos, e gostaríamos de
    poder classifica-los como positivos ou negativos. Abaixo
    seguem alguns exemplos de tweets positivos e negativos.
    Certifique-se de classificar o último tweet corretamente".

    "
    T: Tweet: 'Que dia lindo!'
    P: Este tweet é positivo ou negativo?
    R: positivo

    T: Tweet: 'Eu odeio chuva'
    P: Este tweet é positivo ou negativo?
    R: negativo

    T: Tweet: 'Adoro as aulas do Gusatavo Guanabara'
    P: Este tweet é positivo ou negativo?
    R:
    ".

 - A combinação de diferentes estratégias de prompting pode
   levar a resultados mais poderosos e eficazes.

 - Quase todas as perguntas que você fizer vão misturar vá-
   rias técnicas.

 - Enquanto você continua testando e aprimorando seus prompts,
   pense em como diferentes métodos podem ser combinados para
   conseguir o resultado que você deseja.


Formalizing Prompts

 - Existem algumas partes diferentes em uma pergunta que vai
   ver repetidas vezes. A seguir, veremos a lista das partes
   relevantes.

   * Um papel (agir como um engenheiro ou um professor)
   * Uma instrução ou tarefa (o que fazer)
   * Uma pergunta (qual é a capital do Brasil?)
   * Um contexto (informações adicionais que ajudam a entender
     a pergunta)
   * Exemplos (algumas amostras para guiar a resposta)

 - Nem todas essas partes aparecem em todos os prompts. E
   quando algumas delas aparecem, não há um ordem padrão.

 - Por exemplo, os dois prompts a seguir, que contêm um papel,
   uma instrução e contexto, farão mais ou menos a mesma coisa.

 Exemplo 1:

   "Você é um médico. Leia este histórico médico e preveja os
    riscos para o paciente.
    
    10 de março de 2000: Braço direito fraturado jogando fute-
    bol. Tratado com gesso.

    25 de maio de 2010: Diagnosticado com hipertensão. Lisino-
    pril prescrito.

    15 de setembro de 2015: Desenvolveu pneumonia. Tratado com
    antibióticos e recuperou-se totalmente em poucas semanas.

    8 de setembro de 2023: Sofreu uma consussão em um acidente
    de carro. Internado no hospital e monitorado por 24 horas.
    ".

 Exemplo 2:

   "10 de março de 2000: Braço direito fraturado jogando fute-
    bol. Tratado com gesso.

    25 de maio de 2010: Diagnosticado com hipertensão. Lisino-
    pril prescrito.

    15 de setembro de 2015: Desenvolveu pneumonia. Tratado com
    antibióticos e recuperou-se totalmente em poucas semanas.

    8 de setembro de 2023: Sofreu uma consussão em um acidente
    de carro. Internado no hospital e monitorado por 24 horas.

    Você é um médico. Leia este histórico médico e preveja os
    riscos para o paciente.
    ".

 - Nós preferimos o segundo exemplo, já que a instrução é a
   última parte dele. Isso é melhor porque, no primeiro exem-
   plo, o modelo de linguagem pode acabar escrevendo mais con-
   texto ao ínves de seguir a instrução dada.

 - Se receber a primeira pergunta, o modelo pode acrescentar
   uma nova linha, como: "25 de outubro de 2023: Consulta de
   acompanhamento agendada com neurologista para avaliar a
   recuperação da consussão".

 - Entender a estrutura e os componentes de um prompt é muito
   importante para usar bem os modelos de linguagem de IA.

 - As partes principais de um prompt incluem um papel, uma
   instrução ou tarefa, uma questão, contexto e exemplos.

 - Nem todos os prompts vão ter todos esses elementos, e a
   ordem deles pode variar.

 - No entanto, é geralmente melhor colocar a instrução no
   final para garantir que o modelo se concentre em execu-
   tar a tarefa, em vez de apenas adicionar mais informações.


Chatbot (Talking with robots)

 - No mundo da inteligência artificial, existem vários tipos
   de modelos de linguagem que servem para diferentes objetivos.

 - Os modelos mais usados neste curso são o ChatGPT e p Gemini,
   que são robôes de conversa que "lembram" das mensagens ante-
   riores para que você possa ter um diálogo com ele.

 - Porém esses chatbots não são o único tipo de modelo.

 - Temos outros exemplos como algumas APIs, que, ao contrá-
   rio dos chatbots, não tem "memória", ou seja, a cada cha-
   mada você deve incluir o prompt de preparação novamente
   (ex.: prompt de atuação).

 - Chatbots como o chatGPT são feitos para simular conversas
   interativas. Para ter uma conversa, eles precisam "lembrar"
   de todo os histórico de conversa.

 - Isso sginifica que toda vez que você manda uma nova men-
   sagem, eles releem todas as mensagens anteriores que vocês
   dois enviaram, já que eles não tem uma memória de verdade.

 - Essa "memória" de conversa é o único fator importante
   que os diferencia de modelos que não são chatbots.

 Tokens

 - ChatGPT e outros modelo de IA não leem palavras do mesmo
   jeito que nós.

 - Enquanto nós lemos a frase "Eu não gosto de ovos" palavra
   por palavra, eles podem dividir isso em sua própria versão
   de palavras e ler assim: Eu, não, gosto, de, ovos.

 - Essas "palavras" são chamadas de tokens, e quase toda IA
   moderna usa isso. Cada token vira uma lista de números
   para a IA conseguir processar.

 - Você não precisa saber por que as IAs usam tokens, mas é
   importante entender isso quando se fala de comprimento de
   contexto.

 Comprimento de Contexto

  - Comprimento de contexto se refere à quantidade de texto que
    um modelo de linguagem pode considerar ao gerar uma res-
    posta.

 - Tanto para chatbots quanto para outros modelos, existe um
   limite máximo.

 - Se a conversa ou texto ultrapassar esse limite, o modelo
   não vai conseguir "lembrar" de toda a conversa na hora de
   responder. Por isso as vezes é preciso repetir informações
   importantes.

 - Escolher qual IA usar levando em consideração o número de
   tokens, as vezes é um equilibrio entre preço e a neces-
   sidade de um contexto mais longo.


Prompt Preparation

 Iniciando a Conversa

 - Você pode definir a estrutura e o estilo de uma conversa
   usando sua primeira pergunta para "preparar" um chatbot.

 - Isso te da um controle mais detalhado sobre toda a conver-
   sa. Vamos ver como podemos organizar e dar estilo à conver-
   sa usando uma pergunta inicial, com alguns exemplos.

 Dando Estilo à Conversa

 - Um exemplo divertido de como dar estilo a uma conversa é
   fazer a IA falar como um palhaço. Vamos usar uma pergunta
   que define um papel para preparar o chatbot. Experimente
   digitar essas perguntas no ChatGPT.

 Exemplo 1:

   "Agora você é o palhaço Guaná. Sempre fale como um palhaço.
    Comece se apresentando".

 - Para o resto da conversa, a IA deve falar como um palhaço.
   Embora talvez não seja muito útil ter uma IA que fale como
   um palhaço, esse exemplo mostra que preparar o chatbot com
   um prompt inicial pode ser muito eficaz para controlar o
   estilo da conversa.

 Estruturando a Conversa

  - Além de dar estilo às respostas da IA, também podemos
    controlar a estrutura delas. Por exemplo, considere o
    prompt inicial abaixo.

 Exemplo 2:

   "Por favor, atue como assistente de redação. Cada vez que
    eu lhe der um texto para revisão, responda neste formato:

    Nível de redação: (por exemplo, ensino médio, faculdade)

    Bem escrito: (sim, não ou algo assim)

    Conselhos de redação: Conselhos de formato livre sobre a
    redação.

    Se você entendeu, basta dizer 'SIM'
    ".

 - Ao definir um formato específico para as respostas da IA,
   os usuários podem receber informações de forma consistente
   e organizada.

 - Isso é especialmente útil em aplicações como assistência
   na escrita, onde um feedback estruturado pode ajudar a
   melhorar, e na gestão de projetos, onde a IA pode ser 
   usada para acompanhar tarefas, fornecer atualizações e
   gerenciar cronogramas.


 Instruções para casos especiais

 - Essas instruções são usadas para verificar coisas específicas
   na entrada do usuário e responder de acordo.

 - Isso pode incluir a checagem de comentários tóxicos, tenta-
   tivas de burlar o sistema ou estudantes tentando usar a IA
   para colar.

 - Vamos ver um exemplo de uma instrução especial que impede
   os alunos de fazerem a IA dar a resposta para eles.

 Exemplo 3:

   "Eu gostaria que você atuasse como meu professor de matemá-
    tica. Quando eu lhe apresentar um problema, dê-me conselhos
    sobre o próximo passo de devo tentar. Se algum dia eu pedir
    a resposta, diga 'Desculpe, não posso lhe dar uma resposta'.
    Se você entendeu, diga 'SIM'".

 - Os prompts de preparação são ferramentas poderosas para
   controlar o estilo, a estrutura e o conteúdo de uma con-
   versa com um modelo de IA.


Armadilhas dos LLMs

 - Conheça as falhas das IAs para não cair em roubadas.

 Possíveis Falhas

   - Modelos de Aprendizado de Linguagem (LLMs) são ferramentas
     incríveis que mudaram várias áreas da tecnologia, desde o 
     atendimento ao cliente até a criação de conteúdo.

   - No entanto, como qualquer tecnologia, eles têm suas limita-
     ções. Saber quais são essas falhas é fundamental para usar
     os LLMs de forma eficaz e minimizar problemas que possas
     surgir.

   - Esta aula vai discutir algumas dessas falhas comuns, que
     incluem problemas como citação inadequada de fontes, viés,
     ilusões, erros matemáticos e manipulação do comando inicial.

   - Assim, você ficará preparado para entender e utilizar essas
     ferramentas de uma maneira mais consciente e eficaz.

 Citação de Fontes

   - Embora os LLMs possam gerar textos que parecem citar fontes,
     é importante entender que eles não podem citar fontes com
     precisão.

   - Isso acontece porque não têm acesso à internet e não con-
     segue lembrar a origem dos seus dados de treinamento.
     (*atualmente as IAs já possuem acesso a internet).

   - Consequentemente, frequentemente geram fontes que parecem
     plausíveis, mas são completamente inventadas.

   - Essa é uma limitação significativa ao usar LLMs para
     tarefas que eixgem citações de fontes precisas.

   - O problema de citação imprecisa de fonts pode ser ameni-
     zado em certa medida usando LLMs com busca aumentada.

   - Estes são LLMs que têm capacidade de pesquisar na inter-
     net e em outras fontes para fornecer informações mais pre-
     cisas.

 Viés

   - Os LLMs podem apresentar viés em usas rspostas, geran-
     do frequentemente conteúdo estereotipado ou preconcei-
     tuoso.

   - Isso ocorre porque são treinados em grandes conjuntos
     de dados que podem conter informações tendenciosas.

   - Apesar das medidas de segurança implantadas para prevenir
     isso, os LLMs as vezes podem produzir conteúdo sexista,
     racista ou homofóbico.

 Alucinações

   - Os LLMs podem as vezes "alucinar" ou gerar informações
     falsas quando questionados sobre algo que não sabem a 
     resposta.

   - Em vez de declarar que não sabem a resposta, frequente-
     mente produzem uma resposta que soa confiante, mas é
     incorreta.

   - Isso pode levar à disseminação de informações erradas
     e deve ser considerado ao usar LLMs em tarefas que exi-
     gem informações precisas.

   - Assim, é crucial estar atento a essa limitação ao utili-
     zar essas ferramentas para tarefas que demandam precisão
     e confiabilidade nas informações fornecidas.

 Matemática

   - Apesar de suas capacidades avançadas, os LLMs frequen-
     temente têm dificuldades com tarefas matemáticas e po-
     dem fornecer respostas incorretas (mesmo em algo tão
     simples quanto multiplicar dois números).

   - Isso acontece porque são treinados em grandes volumes
     de texto, e a matemática pode exigir uma abordagem
     diferente.

   - O problema com a matemática pode ser parcialmente ali-
     viado ao usar um LLM com ferramentas adicionais, que 
     combinam as capacidades de um LLM com ferramentas espe-
     cializadas para tarefas como matemática.

   - Dessa forma, você fica mais ciente de que, apesar de suas
     habilidades em linguagem, esses modelos têm suas limita-
     ções quando se trata de cálculos matemáticos.

 Manipulação de Prompts

   - Os LLMs podem ser amnipulados ou "hackeados" por usuá-
     rios para gerar conteúdo específico.

   - Isso é conhecido como manipulação de comandos iniciais
     (ou prompt hacking, em inglês) e pode ser usado para
     enganar o LLM para que ele gere conteúdo inadequado ou
     prejudicial.

   - É importantissimo estar ciente desse problema potencial
     ao usar LLMs, especificamente em aplicações voltadas pa-
     ra o público.

   - Assim, fique atento a essa vulnerabilidade ao usar essas
     ferramentas, principalmente em contextos que têm intera-
     ção direta com o público.

 - Em resumo, embora os LLMs sejam ferramentas poderosas e
   versáteis, eles têm suas próprias armadilhas que os usuá-
   rios precisam conhecer.

 - Problemas com a citação precisa de fontes, viés inerente,
   geração de informações falsas, dificuldades com matemática
   e vulnerabilidade à manipulação de prompts são todos desa-
   fios que precisam ser abordados ao usar esses modelos.

 - Ao entender essas limitações, podemos usar os LLMs de for-
   ma mais eficaz e responsável, e trabalhar para melhorar es-
   ses modelos no futuro.

 - Desse modo, ficando ciente desses pontos, você estará mais
   bem preparado para utilizar essas ferramentas de uma ma-
   neira consciente e responsável.


Aplicações da IA

 - Vamos colocar a mão na massa

 Utilizando a IA

   - Agora que aprendemos as técnicas básicas de engenharia de
     prompt, é hora de aprender como usá-las para resolver pro-
     blemas simples do dia a dia.

 Estruturação de Dados

   - Um caso de uso simples e interessante para os LLMs é a
     organização de dados em tabelas.

   - Talvez você tenha vários artigos de notícias ou relatórios
     de ngeócios e gostaria que todos os pontos importantes fos-
     sem resumidos em uma tabela para depois inserir em uma pla-
     nilha ou banco de dados.

   Exemplo

     - "Numa recente apresentação de relatório de negócios, a Gua-
       nabara Corporate, destacou o seu notável crescimento no
       último ano fiscal. Ela compartilhou que a empresa teve um
       aumento de 15% na receita, atingindo R$ 150 milhões, com
       uma margem de lucro de 12% (R$ 18 milhões de lucro líquido).
       O relatório também apresentou um crescimento de 20% em sua
       base de clientes, totalizando agora 150.000 clientes. Além
       disso, as despesas operacionais da empresa aumentaram em
       10%, totalizando R$ 30 milhões, enquanto o número de fun-
       cionários aumentou 25%, resultando em uma força de trabalho
       atual de 1500 funcionários.

       Gere um tabela contendo as informações do texto acima:"

   - Além de pedir para a IA criar relações com conjuntos de da-
     dos, podemos pedir para ser gerado arquivos com esses dados,
     como Html, Pdf, Excel, csv, etc.